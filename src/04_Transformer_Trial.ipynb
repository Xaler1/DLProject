{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 19:46:08.008197: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-17 19:46:08.303217: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 19:46:08.303779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 19:46:08.342110: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 19:46:08.467985: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 19:46:09.770383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# torch and torchvision imports\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "import numpy as np,  matplotlib.pyplot as plt, pandas as pd, pickle\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResnetModel import *\n",
    "from transformer import *\n",
    "writer = SummaryWriter()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/X_train.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/X_train.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m], axes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/X_val.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m], axes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/Y_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRhythm\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/X_train.npz'"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(np.transpose(np.load('./data/X_train.npz')['arr_0'], axes = (0,2,1))).float()\n",
    "X_test = torch.from_numpy(np.transpose(np.load('./data/X_val.npz')['arr_0'], axes = (0,2,1))).float()\n",
    "y_train = pd.read_csv('./data/Y_train.csv')[['Diag', 'Form', 'Rhythm']].to_numpy()\n",
    "y_test = pd.read_csv('./data/Y_val.csv')[['Diag', 'Form', 'Rhythm']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train).int()\n",
    "y_test = torch.from_numpy(y_test).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "x = X_train[0:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_list = []\n",
    "for classes in y_train:\n",
    "    class_list += classes \n",
    "class_list = set(class_list)\n",
    "class_list\n",
    "diagSupclassDict = {val:i for i, val in enumerate(class_list)}\n",
    "diagSupclassDict['Nodiag'] = 5\n",
    "print(diagSupclassDict)\n",
    "\n",
    "train_label_mapping = torch.zeros((X_train.shape[0], len(diagSupclassDict)), dtype=torch.uint8)\n",
    "print(f\"-\"*(1+30+5+35))\n",
    "for i, classes in enumerate(y_train):\n",
    "    for diagclass in classes:\n",
    "        train_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "    if len(classes) == 0:\n",
    "        train_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "    print(f\"|  {str(y_train[i]):>30}  |  {str(train_label_mapping[i]):<30}   |\")\n",
    "\n",
    "test_label_mapping = torch.zeros((X_test.shape[0], len(diagSupclassDict)), dtype=torch.uint8)\n",
    "print(f\"-\"*(1+30+5+35))\n",
    "for i, classes in enumerate(y_test):\n",
    "    for diagclass in classes:\n",
    "        test_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "    if len(classes) == 0:\n",
    "        test_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "    print(f\"|  {str(y_train[i]):>30}  |  {str(test_label_mapping[i]):<30}   |\")\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, train_label_mapping)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, test_label_mapping)\n",
    "x = X_train[0:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Transformer                                   [1000, 3]                 --\n",
      "├─PositionalEncoding: 1-1                     [1, 1000, 12]             --\n",
      "├─TransformerEncoder: 1-2                     [1, 1000, 12]             --\n",
      "│    └─ModuleList: 2-1                        --                        --\n",
      "│    │    └─TransformerEncoderLayer: 3-1      [1, 1000, 12]             3,884\n",
      "│    │    └─TransformerEncoderLayer: 3-2      [1, 1000, 12]             3,884\n",
      "│    │    └─TransformerEncoderLayer: 3-3      [1, 1000, 12]             3,884\n",
      "│    └─LayerNorm: 2-2                         [1, 1000, 12]             24\n",
      "├─Linear: 1-3                                 [1, 1000, 64]             832\n",
      "├─BatchNorm1d: 1-4                            [1000, 64000]             128,000\n",
      "├─Linear: 1-5                                 [1000, 256]               16,384,256\n",
      "├─BatchNorm1d: 1-6                            [1000, 256]               512\n",
      "├─Dropout1d: 1-7                              [1000, 256]               --\n",
      "├─Linear: 1-8                                 [1000, 512]               131,584\n",
      "├─BatchNorm1d: 1-9                            [1000, 512]               1,024\n",
      "├─Dropout1d: 1-10                             [1000, 512]               --\n",
      "├─Linear: 1-11                                [1000, 3]                 1,539\n",
      "===============================================================================================\n",
      "Total params: 16,659,423\n",
      "Trainable params: 16,659,423\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 16.65\n",
      "===============================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 528.86\n",
      "Params size (MB): 66.63\n",
      "Estimated Total Size (MB): 595.53\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Transformer needs X input as (seq_len, batch_size, channels)\"\"\"\n",
    "model = Transformer(nhead=12, num_classes=3, hidden_size=128, depth=3, seq_length=1000).to(device)\n",
    "# resnetModel = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=6).to(device)\n",
    "\n",
    "# resnetModel(X_train[0:1].to(device))\n",
    "print(summary(model.to(device), (1,1000,12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4*1024-23.86)/37.66 #Max batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test AUC metric\"\"\"\n",
    "ml_auroc = MultilabelAUROC(num_labels=3, average=\"macro\", thresholds=None)\n",
    "# ml_auroc(model(X_train[0:10].to(device)), train_label_mapping[0:10].to(device).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Max Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = Transformer(nhead=12, num_classes=3, drop_p=0.25, hidden_size=128, depth=3, seq_length=200).to(device)\n",
    "lr = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 1000-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "lrs = []\n",
    "\n",
    "for i, (signal, labels) in enumerate(train_loader):\n",
    "    idx = np.random.randint(0, 1000-200)\n",
    "    signal = (signal[:, :, idx:idx+200]).to(device).transpose(0,1).transpose(0,2)\n",
    "    labels = labels.to(device)\n",
    "    output = model(signal)\n",
    "    loss = criterion(output, labels.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    train_loss.append(loss.item())\n",
    "    lrs.append(lr)\n",
    "    lr *= 1.1\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr \n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i > 200 or lr > 1:\n",
    "        break\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "lr_max = lrs[np.where(train_loss == train_loss.min())[0]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max = 0.0025/10\n",
    "lr = lr_max\n",
    "epochs = 150\n",
    "criterion = nn.BCELoss()\n",
    "model = Transformer(nhead=12, num_classes=3, drop_p=0.25, hidden_size=128, depth=3, seq_length=200).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs*800\n",
    "T_0 = T_max/5 \n",
    "for t in range(T_max):\n",
    "    if t <= T_0:\n",
    "        lr = 10**(-5) + (t/T_0)*lr_max  \n",
    "    else: \n",
    "        lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6)\n",
    "    lrs.append(lr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "learning_rates = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (signal, labels) in enumerate(train_loader):\n",
    "        for idx in range(800):\n",
    "            signal = (signal[:, :, idx:idx+200]).to(device).transpose(0,1).transpose(0,2)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(signal)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            if t <= T_0:\n",
    "                lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "            else: \n",
    "                lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6) \n",
    "\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = lr \n",
    "            learning_rates.append(lr)\n",
    "            train_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            t+=1\n",
    "            \n",
    "            train_AUC = ml_auroc(outputs, labels.int())\n",
    "            writer.add_scalar(\"Train_Loss\", loss, t)\n",
    "            writer.add_scalar(\"Learning rate\", lr, t)\n",
    "            writer.add_scalar(\"Batch Train AUC\", train_AUC, t)\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(f\"Step: {i+1}/{len(train_loader)}  |  Train loss: {loss.item():.4f}  |  Train AUC: {train_AUC:.4f}\")\n",
    "           \n",
    "\n",
    "    # model.eval()\n",
    "    test_auc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (signal, labels) in enumerate(test_loader):\n",
    "            idx = np.random.randint(0, 1000-200)\n",
    "            signal = (signal[:, :, idx:idx+200]).to(device).transpose(0,1).transpose(0,2)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(signal)\n",
    "            test_auc += ml_auroc(outputs, labels.int())\n",
    "        test_auc /= len(test_loader)\n",
    "    writer.add_scalar(\"Test AUC\", test_auc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.__iter__().__next__()[0].transpose(0,1).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_Auc = 0\n",
    "with torch.no_grad():\n",
    "    for i, (signal, labels) in enumerate(test_loader):\n",
    "        signal = signal.to(device); labels = labels.to(device)\n",
    "        outputs = model(signal)\n",
    "        test_Auc += ml_auroc(outputs, labels.int())\n",
    "\n",
    "test_Auc /= len(test_loader)\n",
    "test_Auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Transformer_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len=1000, emb_size=12):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, emb_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-np.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Transformer):\n",
    "    def __init__(self, emb_size=12, nhead=6, depth=6, hidden_size=128, seq_length=1000, num_classes=5):\n",
    "        super(Transformer, self).__init__(d_model=emb_size, nhead=nhead, num_encoder_layers=depth, num_decoder_layers=depth, dim_feedforward=hidden_size)\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(seq_length, emb_size)\n",
    "        self.decoder = nn.Linear(emb_size, 256)\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.linear2 = nn.Linear(512, 1024)\n",
    "        self.linear3 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def __forward_impl(self, x):\n",
    "        #x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.__forward_impl(x)\n",
    "    \n",
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "\n",
    "model(X_train[0].T.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "print(summary(model, [1000, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.to(device), (1,1000, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
