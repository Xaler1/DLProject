{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:04:50.338041Z",
     "start_time": "2023-11-30T21:04:50.315510300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "data_root = os.path.join(\"./\", \"data/\")\n",
    "\n",
    "x_train = np.load(os.path.join(data_root, \"X_train.npy\"))\n",
    "y_train_raw = pd.read_csv(os.path.join(data_root, \"y_train.csv\"), header=None)\n",
    "\n",
    "# convert strings to corresponding arrays\n",
    "y_train_raw[0] = y_train_raw[0].apply(lambda x: ast.literal_eval(x))\n",
    "y_train_raw = y_train_raw[0].values\n",
    "\n",
    "x_test = np.load(os.path.join(data_root, \"X_test.npy\"))\n",
    "y_test_raw = pd.read_csv(os.path.join(data_root, \"y_test.csv\"), header=None)\n",
    "y_test_raw[0] = y_test_raw[0].apply(lambda x: ast.literal_eval(x))\n",
    "y_test_raw = y_test_raw[0].values\n",
    "\n",
    "class_to_index = {\n",
    "    \"NORM\": 0,\n",
    "    \"MI\": 1,\n",
    "    \"HYP\": 2,\n",
    "    \"STTC\": 3,\n",
    "    \"CD\": 4\n",
    "}\n",
    "\n",
    "# Encoding the labels for multi-label classification\n",
    "y_test = torch.zeros((len(y_test_raw), len(class_to_index)), dtype=torch.float32)\n",
    "for i, classification in enumerate(y_test_raw):\n",
    "    for class_name in classification:\n",
    "        y_test[i, class_to_index[class_name]] = 1\n",
    "\n",
    "y_train = torch.zeros((len(y_train_raw), len(class_to_index)), dtype=torch.float32)\n",
    "for i, classification in enumerate(y_train_raw):\n",
    "    for class_name in classification:\n",
    "        y_train[i, class_to_index[class_name]] = 1\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "\n",
    "# Free up some memory\n",
    "del y_train_raw\n",
    "del y_test_raw"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:08:17.236312800Z",
     "start_time": "2023-11-30T21:08:15.879990100Z"
    }
   },
   "id": "e080b8b33a3a8b96"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:57:22.647709400Z",
     "start_time": "2023-11-30T22:57:22.636699200Z"
    }
   },
   "id": "d29e0e1da2fd7512"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len=1000, emb_size=12):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, emb_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-np.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Transformer):\n",
    "    def __init__(self, emb_size=12, nhead=6, depth=6, hidden_size=128, seq_length=1000, num_classes=5):\n",
    "        super(Transformer, self).__init__(d_model=emb_size, nhead=nhead, num_encoder_layers=depth, num_decoder_layers=depth, dim_feedforward=hidden_size)\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(seq_length, emb_size)\n",
    "        self.decoder = nn.Linear(emb_size, 256)\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.linear2 = nn.Linear(512, 1024)\n",
    "        self.linear3 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:57:22.910353600Z",
     "start_time": "2023-11-30T22:57:22.888832300Z"
    }
   },
   "id": "5f6ca9bf93a33bf1"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion, train_loader, epochs=10, scheduler=None, metric=None):\n",
    "    net = net.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        pbar = tqdm(train_loader, total=len(train_loader))\n",
    "        last_i = 0\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # exact match ratio\n",
    "            acc = metric(y_pred, y.int())\n",
    "            #acc = accuracy_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy().round())\n",
    "            running_loss += loss.item()\n",
    "            running_acc += acc\n",
    "            \n",
    "            if i % 20 == 1:\n",
    "                running_loss /= (i - last_i)\n",
    "                running_acc /= (i - last_i)\n",
    "                pbar.set_description(f\"loss: {running_loss:.4f}, acc: {running_acc:.4f}\")\n",
    "                running_acc = 0.0\n",
    "                running_loss = 0.0\n",
    "                last_i = i\n",
    "                \n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step(loss.item())\n",
    "\n",
    "    return train_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:57:23.130613900Z",
     "start_time": "2023-11-30T22:57:23.110086300Z"
    }
   },
   "id": "c6fc611fbbc3aa9"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4707, acc: 0.7059:  61%|██████    | 186/307 [00:09<00:05, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00185: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4624, acc: 0.7240:  95%|█████████▌| 292/307 [00:14<00:00, 20.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00289: reducing learning rate of group 0 to 2.5000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4553, acc: 0.7335: 100%|██████████| 307/307 [00:15<00:00, 20.21it/s]\n",
      "loss: 0.4761, acc: 0.7007:  18%|█▊        | 56/307 [00:02<00:12, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00360: reducing learning rate of group 0 to 1.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4658, acc: 0.7284:  60%|█████▉    | 183/307 [00:08<00:05, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00486: reducing learning rate of group 0 to 6.2500e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4623, acc: 0.7303:  82%|████████▏ | 252/307 [00:12<00:02, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00557: reducing learning rate of group 0 to 3.1250e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4550, acc: 0.7367: 100%|██████████| 307/307 [00:14<00:00, 20.86it/s]\n",
      "loss: 0.9901, acc: 1.2973:   6%|▌         | 17/307 [00:00<00:14, 20.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00628: reducing learning rate of group 0 to 1.5625e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4622, acc: 0.7277:  29%|██▉       | 89/307 [00:04<00:10, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00699: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.4622, acc: 0.7396: 100%|██████████| 307/307 [00:14<00:00, 21.24it/s]\n",
      "loss: 0.4422, acc: 0.7485: 100%|██████████| 307/307 [00:14<00:00, 21.35it/s]\n",
      "loss: 0.4750, acc: 0.7093: 100%|██████████| 307/307 [00:14<00:00, 21.48it/s]\n",
      "loss: 0.4503, acc: 0.7400: 100%|██████████| 307/307 [00:14<00:00, 21.37it/s]\n",
      "loss: 0.4565, acc: 0.7403: 100%|██████████| 307/307 [00:14<00:00, 21.34it/s]\n",
      "loss: 0.4567, acc: 0.7379: 100%|██████████| 307/307 [00:14<00:00, 21.42it/s]\n",
      "loss: 0.4769, acc: 0.7005: 100%|██████████| 307/307 [00:14<00:00, 21.30it/s]\n",
      "loss: 0.4556, acc: 0.7452: 100%|██████████| 307/307 [00:14<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "metric = MultilabelAUROC(num_labels=len(class_to_index), average=\"macro\", thresholds=None)\n",
    "net = Transformer(nhead=6, hidden_size=512, depth=3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50, verbose=True, cooldown=20, factor=0.5, min_lr=1e-6)\n",
    "train(net, optimizer, criterion, train_loader, epochs=10, scheduler=scheduler, metric=metric)\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:59:48.743433800Z",
     "start_time": "2023-11-30T22:57:23.450704900Z"
    }
   },
   "id": "45a319ed4f13ef0e"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6617, acc: 0.4465:  22%|██▏       | 34/154 [03:39<12:56,  6.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[63], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[61], line 21\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, optimizer, criterion, train_loader, epochs, scheduler, metric)\u001B[0m\n\u001B[0;32m     18\u001B[0m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(net\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 21\u001B[0m train_losses\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# exact match ratio\u001B[39;00m\n\u001B[0;32m     24\u001B[0m acc \u001B[38;5;241m=\u001B[39m metric(y_pred, y\u001B[38;5;241m.\u001B[39mint())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T21:11:58.613148400Z",
     "start_time": "2023-11-30T21:08:18.570790700Z"
    }
   },
   "id": "391e1c2967f9a5ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5be64e10f86524a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
